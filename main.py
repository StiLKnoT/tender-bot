import asyncio
import logging
import os
import re
import sys
import psycopg2
import gspread
from datetime import datetime
from dotenv import load_dotenv

from aiogram import Bot, Dispatcher, types, F
from aiogram.filters import Command
from aiogram.types import FSInputFile
from aiogram.utils.keyboard import InlineKeyboardBuilder, ReplyKeyboardBuilder
from playwright.async_api import async_playwright

# === 1. CONFIGURATION ===
load_dotenv(encoding="utf-8")

BOT_TOKEN = os.getenv("BOT_TOKEN")
ADMIN_CHANNEL_ID = os.getenv("ADMIN_CHANNEL_ID")
DEFAULT_PHOTO_PATH = os.path.join("img", "default_photo.jpeg")

# Database Configuration
DB_CONFIG = {
    "dbname": os.getenv("DB_NAME"),
    "user": os.getenv("DB_USER"),
    "password": os.getenv("DB_PASS"),
    "host": os.getenv("DB_HOST"),
    "port": os.getenv("DB_PORT")
}

# Google Sheets Configuration
GOOGLE_KEY_FILE = os.getenv("GOOGLE_KEY_PATH", "google_key.json")
GOOGLE_SHEET_NAME = os.getenv("GOOGLE_SHEET_NAME", "–°–ø–∏—Å–æ–∫ —Ç–µ–Ω–¥–µ—Ä–æ–≤")

# Parser Settings
MAX_PAGES_PER_RUN = 5
MIN_PRICE_LIMIT = 5000000  # 5 Million SUM

TARGET_KEYWORDS = [
    "–£—Å–ª—É–≥–∏ –ø–µ—á–∞—Ç–Ω—ã–µ", "–∑–≤—É–∫–æ- –∏ –≤–∏–¥–µ–æ–∑–∞–ø–∏—Å–µ–π", "–ø—Ä–æ–≥—Ä–∞–º–º–Ω—ã—Ö —Å—Ä–µ–¥—Å—Ç–≤",
    "–û–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–µ", "—ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–æ–µ –∏ –æ–ø—Ç–∏—á–µ—Å–∫–æ–µ", "–û–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–æ–µ",
    "–£—Å–ª—É–≥–∏ —Ç–µ–ª–µ–∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–æ–Ω–Ω—ã–µ", "–ü—Ä–æ–¥—É–∫—Ç—ã –ø—Ä–æ–≥—Ä–∞–º–º–Ω—ã–µ",
    "—Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ –ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ–≥–æ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è", "–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã—Ö —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π", "–£—Å–ª—É–≥–∏ –≥–æ–ª–æ–≤–Ω—ã—Ö –æ—Ñ–∏—Å–æ–≤",
    "—É—Å–ª—É–≥–∏ –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ç–∏–≤–Ω—ã–µ", "–Ω–∞—É—á–Ω—ã–º–∏ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è–º–∏", "—ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–º–∏ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞–º–∏",
    "–£—Å–ª—É–≥–∏ —Ä–µ–∫–ª–∞–º–Ω—ã–µ", "–∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—é –∫–æ–Ω—ä—é–Ω–∫—Ç—É—Ä—ã —Ä—ã–Ω–∫–∞", "–£—Å–ª—É–≥–∏ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–µ, –Ω–∞—É—á–Ω—ã–µ –∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ",
    "–≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è", "–≤–æ–µ–Ω–Ω–æ–π –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏", "—Å–æ—Ü–∏–∞–ª—å–Ω–æ–≥–æ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è",
    "–£—Å–ª—É–≥–∏ –≤ –æ–±–ª–∞—Å—Ç–∏ –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è", "–£—Å–ª—É–≥–∏ –≤ –æ–±–ª–∞—Å—Ç–∏ –∑–¥—Ä–∞–≤–æ–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è"
]

REGIONS_LIST = [
    "Respublika Karakalpakstan", "Andijan", "Bukhara", "Jizzakh", "Qashqadaryo",
    "Navoiy", "Namangan", "Samarkand", "Surxondaryo", "Sirdaryo", "Tashkent",
    "Fergana", "Xorazm", "Toshkent shahri", "–ë—É—Ö–∞—Ä—Å–∫–∞—è", "–¢–∞—à–∫–µ–Ω—Ç—Å–∫–∞—è",
    "–°–∞–º–∞—Ä–∫–∞–Ω–¥—Å–∫–∞—è", "–§–µ—Ä–≥–∞–Ω—Å–∫–∞—è", "–ê–Ω–¥–∏–∂–∞–Ω—Å–∫–∞—è", "–ù–∞–º–∞–Ω–≥–∞–Ω—Å–∫–∞—è", "–î–∂–∏–∑–∞–∫—Å–∫–∞—è",
    "–ö–∞—à–∫–∞–¥–∞—Ä—å–∏–Ω—Å–∫–∞—è", "–ù–∞–≤–æ–∏–π—Å–∫–∞—è", "–°—ã—Ä–¥–∞—Ä—å–∏–Ω—Å–∫–∞—è", "–°—É—Ä—Ö–∞–Ω–¥–∞—Ä—å–∏–Ω—Å–∫–∞—è",
    "–•–æ—Ä–µ–∑–º—Å–∫–∞—è", "–†–µ—Å–ø—É–±–ª–∏–∫–∞ –ö–∞—Ä–∞–∫–∞–ª–ø–∞–∫—Å—Ç–∞–Ω", "–≥.–¢–∞—à–∫–µ–Ω—Ç", "–≥. –¢–∞—à–∫–µ–Ω—Ç",
    "Toshkent viloyati", "Tashkent region"
]

TOPIC_MAP = {
    "Xarid.uz": 2, "IT-Market": 4, "Etender": 6, "Cooperation": 8, "XT-Xarid": 10
}

# Initialize Bot
logging.basicConfig(level=logging.INFO)
bot = Bot(token=BOT_TOKEN)
dp = Dispatcher()

# ==========================================
# === 2. DATABASE MANAGEMENT (PostgreSQL) ===
# ==========================================

def get_connection():
    try:
        return psycopg2.connect(**DB_CONFIG)
    except psycopg2.OperationalError as e:
        print(f"‚ùå DB Connection Error: {e}")
        raise e

def init_db():
    conn = get_connection()
    cursor = conn.cursor()
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS tenders (
            id SERIAL PRIMARY KEY,
            source TEXT, title TEXT, description TEXT, price TEXT,
            start_date TEXT, end_date TEXT, link TEXT UNIQUE,
            date_added TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        );
    ''')
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS users (
            user_id BIGINT PRIMARY KEY,
            phone TEXT, username TEXT
        );
    ''')
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS favorites (
            user_id BIGINT,
            tender_id INTEGER,
            timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            PRIMARY KEY (user_id, tender_id),
            FOREIGN KEY (tender_id) REFERENCES tenders(id) ON DELETE CASCADE
        );
    ''')
    conn.commit()
    cursor.close()
    conn.close()

def check_exists(link):
    try:
        conn = get_connection()
        cursor = conn.cursor()
        cursor.execute("SELECT id FROM tenders WHERE link = %s", (link,))
        result = cursor.fetchone()
        conn.close()
        return result is not None
    except: return False

def add_tender_direct(source, title, description, price, start_date, end_date, link):
    try:
        conn = get_connection()
        cursor = conn.cursor()
        cursor.execute("""
            INSERT INTO tenders (source, title, description, price, start_date, end_date, link)
            VALUES (%s, %s, %s, %s, %s, %s, %s)
            ON CONFLICT (link) DO NOTHING
        """, (source, title, description, price, start_date, end_date, link))
        conn.commit()
        conn.close()
        return True
    except Exception as e:
        print(f"DB Error: {e}")
        return False

def get_next_tender(user_id, source):
    conn = get_connection()
    cursor = conn.cursor()
    try:
        query = """
            SELECT id, title, description, price, start_date, end_date, link 
            FROM tenders 
            WHERE source = %s 
            AND id NOT IN (SELECT tender_id FROM favorites WHERE user_id = %s)
            ORDER BY id DESC LIMIT 1
        """
        cursor.execute(query, (source, user_id))
        return cursor.fetchone()
    finally:
        cursor.close()
        conn.close()

def add_favorite(user_id, tender_id):
    conn = get_connection()
    cursor = conn.cursor()
    try:
        cursor.execute("INSERT INTO favorites (user_id, tender_id) VALUES (%s, %s) ON CONFLICT DO NOTHING", (user_id, tender_id))
        conn.commit()
    finally:
        cursor.close()
        conn.close()

def delete_favorite(user_id, tender_id):
    conn = get_connection()
    cursor = conn.cursor()
    try:
        cursor.execute("DELETE FROM favorites WHERE user_id = %s AND tender_id = %s", (user_id, tender_id))
        conn.commit()
    finally:
        cursor.close()
        conn.close()

def get_user_favorites(user_id):
    conn = get_connection()
    cursor = conn.cursor()
    try:
        query = """
            SELECT t.id, t.title, t.price, t.link, t.source 
            FROM favorites f
            JOIN tenders t ON f.tender_id = t.id
            WHERE f.user_id = %s
            ORDER BY f.timestamp DESC
        """
        cursor.execute(query, (user_id,))
        return cursor.fetchall()
    finally:
        cursor.close()
        conn.close()

def get_tender_link(tender_id):
    conn = get_connection()
    cursor = conn.cursor()
    try:
        cursor.execute("SELECT link FROM tenders WHERE id = %s", (tender_id,))
        res = cursor.fetchone()
        return res[0] if res else None
    finally:
        cursor.close()
        conn.close()

# ==========================================
# === 3. HELPER FUNCTIONS ===
# ==========================================

def parse_price_to_number(price_str):
    if not price_str: return 0.0
    try:
        clean = price_str.replace(" ", "").replace("\xa0", "")
        # Remove trailing .00
        if clean.endswith(".00") or clean.endswith(",00"): clean = clean[:-3]
        
        if "," in clean and "." in clean: 
            if clean.find(",") < clean.find("."): clean = clean.replace(",", "") 
            else: clean = clean.replace(".", "").replace(",", ".")
        elif "," in clean: 
            if len(clean) - clean.rfind(",") == 4: clean = clean.replace(",", "")
            else: clean = clean.replace(",", ".")
            
        clean = re.sub(r'[^\d.]', '', clean)
        return float(clean)
    except: return 0.0

def format_price_str(price_raw):
    if not price_raw or "–Ω–µ—Ç" in str(price_raw).lower(): return "–ù–µ —É–∫–∞–∑–∞–Ω–æ"
    try:
        val = parse_price_to_number(str(price_raw))
        if val == 0: return "–ù–µ —É–∫–∞–∑–∞–Ω–æ"
        return "{:,.2f}".format(val).replace(",", " ").replace(".", ",")
    except: return "–ù–µ —É–∫–∞–∑–∞–Ω–æ"

def save_to_google_sheet(source_name, row_data):
    if not os.path.exists(GOOGLE_KEY_FILE): return
    try:
        client = gspread.service_account(filename=GOOGLE_KEY_FILE)
        sheet = client.open(GOOGLE_SHEET_NAME)
        
        try:
            worksheet = sheet.worksheet(source_name)
        except gspread.WorksheetNotFound:
            # === –ó–ê–ì–û–õ–û–í–ö–ò –î–õ–Ø ETENDER (–ë–ï–ó "–¢–µ–∫—É—â–∞—è —Ü–µ–Ω–∞" –∏ "–£—á–∞—Å—Ç–Ω–∏–∫–æ–≤") ===
            if source_name == "Etender":
                cols = "20"
                headers = [
                    "–î–∞—Ç–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞", 
                    "–¢–∏–ø –∞–Ω–∫–µ—Ç—ã", 
                    "–ù–æ–º–µ—Ä –ª–æ—Ç–∞", 
                    "–û–ø–∏—Å–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–æ–≤", 
                    "–ö–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏—è (Toifa)", 
                    "–ó–∞–∫–∞–∑—á–∏–∫", 
                    "–ò–ù–ù –ó–∞–∫–∞–∑—á–∏–∫–∞", 
                    "–ù–∞—á–∞–ª—å–Ω–∞—è —Ü–µ–Ω–∞", 
                    "–í–∞–ª—é—Ç–∞", 
                    # "–¢–µ–∫—É—â–∞—è —Ü–µ–Ω–∞" - –£–ë–†–ê–ù–û
                    "–†–µ–≥–∏–æ–Ω", 
                    "–î–∞—Ç–∞ –Ω–∞—á–∞–ª–∞", 
                    "–°—Ä–æ–∫ –æ–∫–æ–Ω—á–∞–Ω–∏—è", 
                    "–°—Ä–æ–∫ –¥–æ—Å—Ç–∞–≤–∫–∏", 
                    # "–£—á–∞—Å—Ç–Ω–∏–∫–æ–≤" - –£–ë–†–ê–ù–û
                    "–ö–æ–Ω—Ç–∞–∫—Ç—ã", 
                    "–°—Å—ã–ª–∫–∞"
                ]
            elif source_name == "IT-Market":
                cols = "6"
                headers = ["–î–∞—Ç–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞", "–ó–∞–∫–∞–∑—á–∏–∫", "–°—Ç–∞—Ç—É—Å", "–ó–∞–¥–∞—á–∞", "–ë—é–¥–∂–µ—Ç", "–°—Å—ã–ª–∫–∞"]
            else:
                # Xarid.uz (–û–°–¢–ê–í–õ–Ø–ï–ú –ö–ê–ö –ï–°–¢–¨)
                cols = "20"
                headers = [
                    "–î–∞—Ç–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞", "–¢–∏–ø –∞–Ω–∫–µ—Ç—ã", "–ù–æ–º–µ—Ä –ª–æ—Ç–∞", "–û–ø–∏—Å–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–æ–≤", 
                    "–ù–∞–∑–≤–∞–Ω–∏–µ/–ö–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏—è", "–ó–∞–∫–∞–∑—á–∏–∫", "–ù–∞—á–∞–ª—å–Ω–∞—è —Ü–µ–Ω–∞", "–¢–µ–∫—É—â–∞—è —Ü–µ–Ω–∞", 
                    "–†–µ–≥–∏–æ–Ω", "–î–∞—Ç–∞ –Ω–∞—á–∞–ª–∞", "–°—Ä–æ–∫ –æ–∫–æ–Ω—á–∞–Ω–∏—è", "–°—Ä–æ–∫ –¥–æ—Å—Ç–∞–≤–∫–∏", 
                    "–£—á–∞—Å—Ç–Ω–∏–∫–æ–≤", "–ö–æ–Ω—Ç–∞–∫—Ç—ã", "–°—Å—ã–ª–∫–∞"
                ]
            
            worksheet = sheet.add_worksheet(title=source_name, rows="1000", cols=cols)
            worksheet.append_row(headers)
            try:
                body = {"requests": [{"repeatCell": {"range": {"sheetId": worksheet.id, "startRowIndex": 0, "endRowIndex": 1}, "cell": {"userEnteredFormat": {"textFormat": {"bold": True}}}, "fields": "userEnteredFormat.textFormat.bold"}}]}
                sheet.batch_update(body)
            except: pass
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –≤ —Å—Ç—Ä–æ–∫–∏
        safe_row = [str(x) if x is not None else "" for x in row_data]
        worksheet.append_row(safe_row)
        print(f"‚úÖ [Google] –ó–∞–ø–∏—Å–∞–Ω–æ –≤ –ª–∏—Å—Ç '{source_name}'")
        
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ Google Sheets ({source_name}): {e}")

async def send_notification_to_channel(text, source_name, photo_path=None):
    if not ADMIN_CHANNEL_ID: return
    thread_id = TOPIC_MAP.get(source_name)
    try:
        if photo_path and os.path.exists(photo_path):
            photo = FSInputFile(photo_path)
            await bot.send_photo(chat_id=ADMIN_CHANNEL_ID, photo=photo, caption=text, parse_mode="HTML", message_thread_id=thread_id)
        else:
            await bot.send_message(chat_id=ADMIN_CHANNEL_ID, text=text, parse_mode="HTML", message_thread_id=thread_id, disable_web_page_preview=True)
    except Exception as e:
        print(f"‚ö†Ô∏è Telegram Error: {e}")

# ==========================================
# === 4. PARSING LOGIC: ETENDER ===
# ==========================================

# ==========================================
# === 3. –§–£–ù–ö–¶–ò–Ø –ó–ê–ü–ò–°–ò –í GOOGLE SHEETS ===
# ==========================================

def save_to_google_sheet(source_name, row_data):
    if not os.path.exists(GOOGLE_KEY_FILE): return
    try:
        client = gspread.service_account(filename=GOOGLE_KEY_FILE)
        sheet = client.open(GOOGLE_SHEET_NAME)
        
        try:
            worksheet = sheet.worksheet(source_name)
        except gspread.WorksheetNotFound:
            # === –°–û–ó–î–ê–ù–ò–ï –õ–ò–°–¢–ê –° –ü–†–ê–í–ò–õ–¨–ù–´–ú–ò –ó–ê–ì–û–õ–û–í–ö–ê–ú–ò ===
            if source_name == "Etender":
                cols = "20"
                headers = [
                    "–î–∞—Ç–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞", 
                    "–¢–∏–ø –∞–Ω–∫–µ—Ç—ã", 
                    "–ù–æ–º–µ—Ä –ª–æ—Ç–∞", 
                    "–û–ø–∏—Å–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–æ–≤", 
                    "–ö–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏—è (Toifa)", 
                    "–ò–ù–ù –ó–∞–∫–∞–∑—á–∏–∫–∞",  # <--- –¢–ï–ü–ï–†–¨ –°–ù–ê–ß–ê–õ–ê –ò–ù–ù
                    "–ó–∞–∫–∞–∑—á–∏–∫",       # <--- –ü–û–¢–û–ú –ó–ê–ö–ê–ó–ß–ò–ö
                    "–ù–∞—á–∞–ª—å–Ω–∞—è —Ü–µ–Ω–∞", 
                    "–í–∞–ª—é—Ç–∞", 
                    # "–¢–µ–∫—É—â–∞—è —Ü–µ–Ω–∞" - –£–ë–†–ê–ù–û
                    "–†–µ–≥–∏–æ–Ω", 
                    "–î–∞—Ç–∞ –Ω–∞—á–∞–ª–∞", 
                    "–°—Ä–æ–∫ –æ–∫–æ–Ω—á–∞–Ω–∏—è", 
                    "–°—Ä–æ–∫ –¥–æ—Å—Ç–∞–≤–∫–∏", 
                    # "–£—á–∞—Å—Ç–Ω–∏–∫–æ–≤" - –£–ë–†–ê–ù–û
                    "–ö–æ–Ω—Ç–∞–∫—Ç—ã", 
                    "–°—Å—ã–ª–∫–∞"
                ]
            elif source_name == "IT-Market":
                cols = "6"
                headers = ["–î–∞—Ç–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞", "–ó–∞–∫–∞–∑—á–∏–∫", "–°—Ç–∞—Ç—É—Å", "–ó–∞–¥–∞—á–∞", "–ë—é–¥–∂–µ—Ç", "–°—Å—ã–ª–∫–∞"]
            else:
                # Xarid.uz (—Å—Ç–∞–Ω–¥–∞—Ä—Ç)
                cols = "20"
                headers = [
                    "–î–∞—Ç–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞", "–¢–∏–ø –∞–Ω–∫–µ—Ç—ã", "–ù–æ–º–µ—Ä –ª–æ—Ç–∞", "–û–ø–∏—Å–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–æ–≤", 
                    "–ù–∞–∑–≤–∞–Ω–∏–µ/–ö–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏—è", "–ó–∞–∫–∞–∑—á–∏–∫", "–ù–∞—á–∞–ª—å–Ω–∞—è —Ü–µ–Ω–∞", "–¢–µ–∫—É—â–∞—è —Ü–µ–Ω–∞", 
                    "–†–µ–≥–∏–æ–Ω", "–î–∞—Ç–∞ –Ω–∞—á–∞–ª–∞", "–°—Ä–æ–∫ –æ–∫–æ–Ω—á–∞–Ω–∏—è", "–°—Ä–æ–∫ –¥–æ—Å—Ç–∞–≤–∫–∏", 
                    "–£—á–∞—Å—Ç–Ω–∏–∫–æ–≤", "–ö–æ–Ω—Ç–∞–∫—Ç—ã", "–°—Å—ã–ª–∫–∞"
                ]
            
            worksheet = sheet.add_worksheet(title=source_name, rows="1000", cols=cols)
            worksheet.append_row(headers)
            try:
                body = {"requests": [{"repeatCell": {"range": {"sheetId": worksheet.id, "startRowIndex": 0, "endRowIndex": 1}, "cell": {"userEnteredFormat": {"textFormat": {"bold": True}}}, "fields": "userEnteredFormat.textFormat.bold"}}]}
                sheet.batch_update(body)
            except: pass
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ (int –æ—Å—Ç–∞–≤–ª—è–µ–º int, –æ—Å—Ç–∞–ª—å–Ω–æ–µ str)
        safe_row = []
        for x in row_data:
            if isinstance(x, float) and x.is_integer():
                safe_row.append(int(x))
            elif x is None:
                safe_row.append("")
            else:
                safe_row.append(x)

        worksheet.append_row(safe_row, value_input_option="USER_ENTERED")
        print(f"‚úÖ [Google] –ó–∞–ø–∏—Å–∞–Ω–æ –≤ –ª–∏—Å—Ç '{source_name}'")
        
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ Google Sheets ({source_name}): {e}")

# ==========================================
# === 4. –ü–ê–†–°–ò–ù–ì ETENDER (–§–ò–ù–ê–õ–¨–ù–´–ô) ===
# ==========================================

async def get_etender_details(page, link):
    """
    –î–µ—Ç–∞–ª—å–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ Etender (–°—Ç—Ä–æ–≥–∏–π —Ñ–∏–ª—å—Ç—Ä: —Ç–æ–ª—å–∫–æ –Ω–∞–∑–≤–∞–Ω–∏—è –ª–æ—Ç–æ–≤ "1 - –ù–∞–∑–≤–∞–Ω–∏–µ")
    """
    data = {
        "customer": "–ù–µ —É–∫–∞–∑–∞–Ω", "inn": "–ù–µ —É–∫–∞–∑–∞–Ω", "contact": "–ù–µ —É–∫–∞–∑–∞–Ω", 
        "start_date": "–ù–µ —É–∫–∞–∑–∞–Ω–∞", "end_date": "–ù–µ —É–∫–∞–∑–∞–Ω–∞", 
        "delivery_term": "–ù–µ —É–∫–∞–∑–∞–Ω", "items_desc": "–¢–µ–Ω–¥–µ—Ä", "toifa": "–¢–µ–Ω–¥–µ—Ä",
        "participants": "0" 
    }
    
    try:
        # === 1. –û–ü–ò–°–ê–ù–ò–ï (–°–¢–†–û–ì–ò–ô –†–ï–ñ–ò–ú) ===
        items_list = []
        try:
            # –ò—â–µ–º –≤—Å–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã —Å –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏
            # .lot__products__item - —ç—Ç–æ –Ω–∞–∏–±–æ–ª–µ–µ —Ç–æ—á–Ω—ã–π –∫–ª–∞—Å—Å –¥–ª—è —Å–ø–∏—Å–∫–∞ —Ç–æ–≤–∞—Ä–æ–≤ –Ω–∞ Etender
            # h4, .lot-title - –∑–∞–ø–∞—Å–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã
            titles = page.locator(".lot__products__item, h4, h5, .card-title, .lot-title")
            count = await titles.count()
            
            for i in range(count):
                raw_text = await titles.nth(i).inner_text()
                
                # –†–∞–∑–±–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ (—Ç–∞–∫ –∫–∞–∫ –≤ –æ–¥–Ω–æ–º –±–ª–æ–∫–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –∏ –Ω–∞–∑–≤–∞–Ω–∏–µ, –∏ —Ü–µ–Ω–∞)
                lines = raw_text.split('\n')
                
                for line in lines:
                    clean_line = line.strip()
                    # === –ì–õ–ê–í–ù–´–ô –§–ò–õ–¨–¢–† ===
                    # –ò—â–µ–º —Å—Ç—Ä–æ–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –Ω–∞—á–∏–Ω–∞—é—Ç—Å—è —Å—Ç—Ä–æ–≥–æ —Å "–¶–∏—Ñ—Ä–∞" + " - "
                    # –ü—Ä–∏–º–µ—Ä: "1 - –ó–∞–ø–∞—Å–Ω—ã–µ —á–∞—Å—Ç–∏..."
                    # ^ - –Ω–∞—á–∞–ª–æ —Å—Ç—Ä–æ–∫–∏, \d+ - —Ü–∏—Ñ—Ä—ã, \s* - –ø—Ä–æ–±–µ–ª—ã, - - —Ç–∏—Ä–µ
                    if re.match(r'^\d+\s*-\s+', clean_line):
                        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∑–∞—â–∏—Ç–∞: –µ—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∞—è (–º–µ–Ω–µ–µ 5 —Å–∏–º–≤), —ç—Ç–æ –º—É—Å–æ—Ä
                        if len(clean_line) > 5:
                            items_list.append(clean_line)
            
            # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ —Ç–æ–≤–∞—Ä—ã –ø–æ —à–∞–±–ª–æ–Ω—É - —Å–æ—Ö—Ä–∞–Ω—è–µ–º
            if items_list: 
                # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã (dict.fromkeys) –∏ –±–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 10
                unique_items = list(dict.fromkeys(items_list))
                data["items_desc"] = "\n".join(unique_items[:10])
            else:
                # –ó–ê–ü–ê–°–ù–û–ô –í–ê–†–ò–ê–ù–¢: –ï—Å–ª–∏ —à–∞–±–ª–æ–Ω–∞ "1 - ..." –Ω–µ—Ç, –±–µ—Ä–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ H1
                h1 = page.locator("h1").first
                if await h1.count() > 0: 
                    data["items_desc"] = (await h1.inner_text()).strip()

        except Exception as e:
            # print(f"Error parsing desc: {e}")
            pass

        # === 2. –ö–í–ê–õ–ò–§–ò–ö–ê–¶–ò–Ø (TOIFA) ===
        try:
            toifa_el = page.locator("td:nth-child(4)").first
            if await toifa_el.count() > 0: 
                data["toifa"] = (await toifa_el.inner_text()).strip()
        except: pass

        # –ü–æ–ª—É—á–∞–µ–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç –¥–ª—è –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –ø–æ–ª–µ–π
        raw_text = await page.inner_text("body")
        clean_text = " ".join(raw_text.split())

        # === 3. –ó–ê–ö–ê–ó–ß–ò–ö ===
        cust_match = re.search(
            r"(?:Buyurtmachi nomi|Name of the customer|–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∑–∞–∫–∞–∑—á–∏–∫–∞)[\s:]+([^\n\r]+?)(?:Buyurtmachi|Telefon|Manzil|Address|Stir|Rasmiylashtirish|Takliflarni|Ishtirokchi|Eng yaxshi|$)", 
            clean_text, 
            re.IGNORECASE
        )
        if cust_match: 
            data["customer"] = cust_match.group(1).strip()[:150]

        # 4. –ò–ù–ù
        inn_match = re.search(r"(?:STIR|INN|–ò–ù–ù)[\s:]+(\d{9})", clean_text, re.IGNORECASE)
        if inn_match: data["inn"] = inn_match.group(1)

        # 5. –î–ê–¢–´
        start_match = re.search(r"(?:Boshlanish|Start|–ù–∞—á–∞–ª–æ)[\w\W]{0,60}?(\d{2}[.-]\d{2}[.-]\d{4}(?:\s*\d{2}:\d{2})?)", clean_text, re.IGNORECASE)
        if start_match: data["start_date"] = start_match.group(1)
        
        end_match = re.search(r"(?:Tugash|End|–û–∫–æ–Ω—á–∞–Ω–∏|Muddat)[\w\W]{0,60}?(\d{2}[.-]\d{2}[.-]\d{4}(?:\s*\d{2}:\d{2})?)", clean_text, re.IGNORECASE)
        if end_match: data["end_date"] = end_match.group(1)

        # 6. –ö–û–ù–¢–ê–ö–¢–´
        phone_match = re.search(r"(?:Telefon|Phone|–¢–µ–ª–µ—Ñ–æ–Ω)[\s:]+([+\d\(\)\s-]{9,20})", clean_text, re.IGNORECASE)
        if phone_match: data["contact"] = phone_match.group(1).strip()

        # 7. –°–†–û–ö –ü–û–°–¢–ê–í–ö–ò
        deliv_match = re.search(r"(?:Muddati|Yetkazib|Delivery|–°—Ä–æ–∫)[\s:]+([\w\d\s]+?)(?:kun|day|oy|–º–µ—Å|$)", clean_text, re.IGNORECASE)
        if deliv_match: data["delivery_term"] = deliv_match.group(0).strip()

    except Exception as e: pass
    return data

async def parse_etender(page):
    url = "https://etender.uzex.uz/lots/1/0"
    source_name = "Etender"
    print(f"üî∏ –ü—Ä–æ–≤–µ—Ä—è—é {source_name}...")
    
    # === –°–ü–ò–°–û–ö –†–ê–ó–†–ï–®–ï–ù–ù–´–• –ö–ê–¢–ï–ì–û–†–ò–ô ===
    ALLOWED_TOIFA = [
        "–û–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–µ, —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–æ–µ –∏ –æ–ø—Ç–∏—á–µ—Å–∫–æ–µ",
        "–û–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–æ–µ",
        "–ü—Ä–æ–¥—É–∫—Ç—ã –ø—Ä–æ–≥—Ä–∞–º–º–Ω—ã–µ", 
        "—É—Å–ª—É–≥–∏ –ø–æ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ –ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ–≥–æ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è",
        "–ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–æ–Ω–Ω—ã–µ –∏ –∞–Ω–∞–ª–æ–≥–∏—á–µ—Å–∫–∏–µ —É—Å–ª—É–≥–∏ –≤ –æ–±–ª–∞—Å—Ç–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã—Ö —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π",
        "–£—Å–ª—É–≥–∏ –≤ –æ–±–ª–∞—Å—Ç–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã—Ö —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π"
    ]
    
    try:
        await page.goto(url, timeout=90000, wait_until="networkidle")
        try: await page.wait_for_selector("a[href^='/lot/']", timeout=20000)
        except: return

        page_num = 1
        while page_num <= MAX_PAGES_PER_RUN:
            lot_links = page.locator("a[href^='/lot/']")
            count = await lot_links.count()
            print(f"üîé Etender: –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}, –Ω–∞–π–¥–µ–Ω–æ —Å—Å—ã–ª–æ–∫: {count}")
            if count == 0: break
            new_items = 0
            
            all_links = []
            for i in range(count):
                href = await lot_links.nth(i).get_attribute("href")
                all_links.append(f"https://etender.uzex.uz{href}")

            for full_link in all_links:
                try:
                    if check_exists(full_link): continue

                    detail_page = await page.context.new_page()
                    await detail_page.goto(full_link, wait_until="networkidle")
                    
                    full_page_text = await detail_page.inner_text("body")
                    clean_page_text = " ".join(full_page_text.split())
                    
                    details = await get_etender_details(detail_page, full_link)

                    # === –§–ò–õ–¨–¢–† –ü–û –ö–ê–¢–ï–ì–û–†–ò–Ø–ú (TOIFA) ===
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ 'toifa' –æ–¥–Ω—É –∏–∑ —Ä–∞–∑—Ä–µ—à–µ–Ω–Ω—ã—Ö —Ñ—Ä–∞–∑
                    current_toifa = details['toifa'].lower()
                    is_allowed_category = any(cat.lower() in current_toifa for cat in ALLOWED_TOIFA)

                    if not is_allowed_category:
                        # –ï—Å–ª–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏—è –Ω–µ –ø–æ–¥—Ö–æ–¥–∏—Ç, –∑–∞–∫—Ä—ã–≤–∞–µ–º –∏ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                        # print(f"üö´ –ü—Ä–æ–ø—É—Å–∫ (–ö–∞—Ç–µ–≥–æ—Ä–∏—è): {details['toifa']}") 
                        await detail_page.close()
                        continue
                    # ====================================

                    start_price_raw = "0"
                    currency_code = "UZS"
                    price_regex = r"(\d[\d\s,.]+)\s*(UZS|USD|RUB|EUR|so.?m|—Å—É–º|ye)"
                    
                    context_match = re.search(r"(?:Boshlang|Start|–ù–∞—á–∞–ª—å–Ω–∞—è|–ë—é–¥–∂–µ—Ç)[\w\W]{0,50}?" + price_regex, clean_page_text, re.IGNORECASE)
                    if context_match:
                        start_price_raw = context_match.group(1).strip()
                        currency_code = context_match.group(2).upper().strip()
                    else:
                        simple_match = re.search(price_regex, clean_page_text)
                        if simple_match:
                            start_price_raw = simple_match.group(1).strip()
                            currency_code = simple_match.group(2).upper().strip()

                    if "SO" in currency_code or "–°–£–ú" in currency_code: currency_code = "UZS"
                    if "YE" in currency_code: currency_code = "USD"

                    start_price_num = parse_price_to_number(start_price_raw)
                    if len(str(int(start_price_num))) > 15: start_price_num = 0.0
                    
                    limit = MIN_PRICE_LIMIT
                    if currency_code != "UZS": limit = 100

                    if start_price_num < limit: 
                        await detail_page.close(); continue

                    await detail_page.close()

                    lot_id = full_link.split("/")[-1]
                    region = next((r for r in REGIONS_LIST if r.lower() in clean_page_text.lower()), "–ù–µ —É–∫–∞–∑–∞–Ω")
                    
                    sheet_start_price = int(start_price_num) if start_price_num > 0 else 0
                    
                    full_price_db = f"{start_price_num} {currency_code}"
                    full_desc = f"Tender||{region}||{currency_code}"
                    add_tender_direct(source_name, f"–õ–æ—Ç ‚Ññ{lot_id}", full_desc, full_price_db, details['start_date'], details['end_date'], full_link)
                    
                    print(f"üî• [Etender] –ù–æ–≤—ã–π: {lot_id} | {start_price_num} {currency_code}")

                    msg = (
                        f"<b>–¢–∏–ø –∞–Ω–∫–µ—Ç—ã: –¢–µ–Ω–¥–µ—Ä</b>\n–ò—Å—Ç–æ—á–Ω–∏–∫: etender.uzex.uz\n\n"
                        f"üî¢ <b>–ù–æ–º–µ—Ä –ª–æ—Ç–∞:</b> {lot_id}\n"
                        f"üìÇ <b>–û–ø–∏—Å–∞–Ω–∏–µ:</b> {details['items_desc'][:200]}...\n"
                        f"üìÅ <b>–ö–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏—è:</b> {details['toifa']}\n"
                        f"üìç <b>–†–∞–π–æ–Ω:</b> {region}\n"
                        f"üìÖ <b>–î–∞—Ç–∞ –Ω–∞—á–∞–ª–∞:</b> {details['start_date']}\n"
                        f"‚è≥ <b>–°—Ä–æ–∫ –æ–∫–æ–Ω—á–∞–Ω–∏—è:</b> {details['end_date']}\n"
                        f"üí∞ <b>–ë—é–¥–∂–µ—Ç:</b> {format_price_str(str(start_price_num))} {currency_code}\n"
                        f"üîó <b>–°—Å—ã–ª–∫–∞:</b> {full_link}\n\n"
                        f"üè¢ <b>–ó–∞–∫–∞–∑—á–∏–∫:</b> {details['customer']}\n"
                        f"üî¢ <b>–ò–ù–ù:</b> {details['inn']}\n"
                        f"üìû <b>–ö–æ–Ω—Ç–∞–∫—Ç—ã:</b> {details['contact']}"
                    )
                    await send_notification_to_channel(msg, source_name, DEFAULT_PHOTO_PATH)
                    
                    # === –ó–ê–ü–ò–°–¨ –í GOOGLE SHEETS ===
                    save_to_google_sheet("Etender", [
                        datetime.now().strftime("%d.%m.%Y %H:%M"), 
                        "–¢–µ–Ω–¥–µ—Ä", 
                        lot_id, 
                        details['items_desc'], 
                        details['toifa'], 
                        details['inn'],      
                        details['customer'], 
                        sheet_start_price, 
                        currency_code, 
                        region, 
                        details['start_date'], 
                        details['end_date'], 
                        details['delivery_term'], 
                        details['contact'], 
                        full_link
                    ])
                    new_items += 1

                except Exception as e:
                    continue
            
            if new_items == 0 and page_num > 1: break
            try:
                next_btn = page.locator("li.pagination-next a").first
                if await next_btn.is_visible(): await next_btn.click(); await page.wait_for_timeout(5000); page_num += 1
                else: break
            except: break
    except: pass

# ==========================================
# === 5. PARSING LOGIC: XARID.UZ (ORIGINAL) ===
# ==========================================

async def get_xarid_details(page, link):
    data = {"customer": "–ù–µ —É–∫–∞–∑–∞–Ω", "contact": "–ù–µ —É–∫–∞–∑–∞–Ω", "participants": "0", "start_date": "–ù–µ —É–∫–∞–∑–∞–Ω–∞", "end_date": "–ù–µ —É–∫–∞–∑–∞–Ω–∞", "delivery_term": "–ù–µ —É–∫–∞–∑–∞–Ω", "items_desc": "–ù–µ —É–∫–∞–∑–∞–Ω–æ"}
    try:
        await page.goto(link, timeout=45000, wait_until="domcontentloaded"); await page.wait_for_timeout(2500)
        raw_text = await page.inner_text("body")
        found_items = []; raw_items = re.findall(r"(?:^|\n)\s*(?:\d+[.\s]*)?([^\n]+?)\s*\(\d{2}\.\d{2}\.\d{2}[\.\d-]*\)", raw_text)
        if raw_items:
            for idx, item_name in enumerate(raw_items):
                if len(item_name.strip()) > 2: found_items.append(f"{idx + 1}. {item_name.strip()}")
            if found_items: data["items_desc"] = "\n".join(found_items)
        
        for word in ["Texnik yordam", "Call-markaz", "Ishonch telefoni", "–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞"]:
            if word in raw_text: raw_text = raw_text.split(word)[0]
        clean_oneline = " ".join(raw_text.split())

        # –ò–°–ü–†–ê–í–õ–ï–ù–û: –¢–µ–ø–µ—Ä—å group(1) - —ç—Ç–æ –∑–Ω–∞—á–µ–Ω–∏–µ, group(0) - –≤—Å–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
        cust_match = re.search(r"(?:Buyurtmachining\s*nomi|–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ\s*–∑–∞–∫–∞–∑—á–∏–∫–∞)\s*:?\s*(.*?)(?:Boshlanish|Start|–î–∞—Ç–∞|Manzil|–ê–¥—Ä–µ—Å)", clean_oneline, re.IGNORECASE)
        if cust_match: data["customer"] = cust_match.group(1).strip()

        phone_match = re.search(r"Bog.?lanish\s*uchun\s*:?\s*([+\d\(\)\s-]{7,25})", clean_oneline, re.IGNORECASE)
        if phone_match and any(c.isdigit() for c in phone_match.group(1)): data["contact"] = phone_match.group(1).strip()
        
        # –ò–°–ü–†–ê–í–õ–ï–ù–û: –¢–µ–ø–µ—Ä—å group(1) - —ç—Ç–æ –∑–Ω–∞—á–µ–Ω–∏–µ
        deliv_match = re.search(r"(?:Yetkazib\s*berish\s*muddati|–°—Ä–æ–∫\s*–ø–æ—Å—Ç–∞–≤–∫–∏)\s*:?\s*(.*?)(?:Fayl|Status|–°—Ç–∞—Ç—É—Å)", clean_oneline, re.IGNORECASE)
        if deliv_match: data["delivery_term"] = deliv_match.group(1).strip()

        start_match = re.search(r"(?:Boshlanish\s*sanasi|–î–∞—Ç–∞\s*–Ω–∞—á–∞–ª–∞).*?(\d{2}\.\d{2}\.\d{4}\s*\d{2}:\d{2}(?::\d{2})?)", clean_oneline, re.IGNORECASE)
        if start_match: data["start_date"] = start_match.group(1)
        end_match = re.search(r"(?:Tugash\s*sanasi|–î–∞—Ç–∞\s*–æ–∫–æ–Ω—á–∞–Ω–∏—è).*?(\d{2}\.\d{2}\.\d{4}\s*\d{2}:\d{2}(?::\d{2})?)", clean_oneline, re.IGNORECASE)
        if end_match: data["end_date"] = end_match.group(1)
        part_match = re.search(r"(?:Ishtirokchilar\s*soni|–£—á–∞—Å—Ç–Ω–∏–∫–∏).*?(\d+)", clean_oneline, re.IGNORECASE)
        if part_match: data["participants"] = part_match.group(1)
    except: pass
    return data


async def parse_xarid_uz(page):
    url = "https://xarid.uzex.uz/auction"
    source_name = "Xarid.uz"
    print(f"üî∏ Checking {source_name}...")
    try:
        await page.goto(url, timeout=90000, wait_until="domcontentloaded")
        page_num = 1
        while page_num <= MAX_PAGES_PER_RUN:
            try: await page.wait_for_selector(".lot-item", timeout=15000); items = page.locator(".lot-item"); count = await items.count()
            except: break
            if count == 0: break
            new_items = 0
            for i in range(count):
                item = items.nth(i)
                try:
                    full_text = await item.inner_text(); clean_text = " ".join(full_text.split())
                    if not any(k.lower() in clean_text.lower() for k in TARGET_KEYWORDS): continue
                    match_id = re.search(r'Lot\s*raqami:\s*(\d+)', clean_text, re.IGNORECASE); lot_id = match_id.group(1) if match_id else "00000"
                    
                    # === 1. –ù–ê–ß–ê–õ–¨–ù–ê–Ø –¶–ï–ù–ê ===
                    start_pattern = r"(?:Boshlang.?ich\s*narx|–ù–∞—á–∞–ª—å–Ω–∞—è\s*—Å—Ç–æ–∏–º–æ—Å—Ç—å|–°—Ç–∞—Ä—Ç–æ–≤–∞—è\s*—Å—Ç–æ–∏–º–æ—Å—Ç—å|–ù–∞—á–∞–ª—å–Ω–∞—è\s*—Ü–µ–Ω–∞)[^\d]*([\d\s,.]+)"
                    match_p = re.search(start_pattern, clean_text, re.IGNORECASE)
                    start_price_raw = match_p.group(1) if match_p else "0"
                    start_price_num = parse_price_to_number(start_price_raw)
                    if start_price_num < MIN_PRICE_LIMIT: continue 
                    start_price_str = format_price_str(start_price_raw)

                    full_link = f"https://xarid.uzex.uz/auction/detail/{lot_id[-6:]}"
                    if check_exists(full_link): continue

                    # === 2. –¢–ï–ö–£–©–ê–Ø –¶–ï–ù–ê (–ò–°–ü–†–ê–í–õ–ï–ù–û: –Ω–µ –∑–∞—Ö–≤–∞—Ç—ã–≤–∞—Ç—å –¥–∞—Ç—ã) ===
                    # –ò—â–µ–º —Ü–µ–Ω—É —Ç–æ–ª—å–∫–æ –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö 20 —Å–∏–º–≤–æ–ª–æ–≤ –ø–æ—Å–ª–µ —Å–ª–æ–≤ "–¢–µ–∫—É—â–∞—è —Ü–µ–Ω–∞", —á—Ç–æ–±—ã –Ω–µ —É–ª–µ—Ç–µ—Ç—å –Ω–∞ –¥–∞—Ç—É
                    curr_pattern = r"(?:Joriy\s*narx|–¢–µ–∫—É—â–∞—è\s*—Ü–µ–Ω–∞|–õ—É—á—à–µ–µ\s*–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ)[^\d\n]{0,20}([\d\s,.]+)"
                    match_c = re.search(curr_pattern, clean_text, re.IGNORECASE)
                    
                    current_price_num = 0.0
                    current_price_str = "–ù–µ—Ç —Å—Ç–∞–≤–æ–∫"
                    
                    if match_c: 
                        raw_curr = match_c.group(1)
                        # –î–æ–ø. –ø—Ä–æ–≤–µ—Ä–∫–∞: –µ—Å–ª–∏ –≤ —Å—Ç—Ä–æ–∫–µ –±–æ–ª—å—à–µ –æ–¥–Ω–æ–π —Ç–æ—á–∫–∏, —ç—Ç–æ —Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ –¥–∞—Ç–∞ (25.12.2025)
                        if raw_curr.count('.') < 2:
                            current_price_num = parse_price_to_number(raw_curr)
                            current_price_str = format_price_str(raw_curr)

                    # –ü–û–î–ì–û–¢–û–í–ö–ê –î–õ–Ø EXCEL (INT, –±–µ–∑ .0)
                    sheet_start_price = int(start_price_num) if start_price_num > 0 else 0
                    sheet_current_price = int(current_price_num) if current_price_num > 0 else 0

                    detail_page = await page.context.new_page()
                    details = await get_xarid_details(detail_page, full_link)
                    await detail_page.close()
                    
                    toifa = "–ù–µ —É–∫–∞–∑–∞–Ω–∞"
                    if "Toifa:" in full_text: toifa = full_text.split("Toifa:")[1].split("\n")[0].strip()
                    region = "–ù–µ —É–∫–∞–∑–∞–Ω"
                    for reg in REGIONS_LIST:
                        if reg.lower() in clean_text.lower(): region = reg; break

                    real_end = details['end_date'] if details['end_date'] != "–ù–µ —É–∫–∞–∑–∞–Ω–∞" else "-"
                    real_start = details['start_date'] if details['start_date'] != "–ù–µ —É–∫–∞–∑–∞–Ω–∞" else "-"
                    
                    full_desc = f"{toifa}||{region}||{current_price_str}"
                    add_tender_direct(source_name, f"–õ–æ—Ç ‚Ññ{lot_id}", full_desc, f"{start_price_num} UZS", real_start, real_end, full_link)
                    print(f"üî• [Xarid] New: {lot_id}")
                    
                    msg = (f"<b>–¢–∏–ø –∞–Ω–∫–µ—Ç—ã: –ê—É–∫—Ü–∏–æ–Ω</b>\n–ò—Å—Ç–æ—á–Ω–∏–∫: xarid.uz\n\nüî¢ <b>–ù–æ–º–µ—Ä –ª–æ—Ç–∞:</b> {lot_id}\nüìÇ <b>–ö–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏—è:</b> {toifa}\nüìç <b>–†–∞–π–æ–Ω:</b> {region}\nüìÖ <b>–î–∞—Ç–∞ –Ω–∞—á–∞–ª–∞:</b> {real_start}\n‚è≥ <b>–°—Ä–æ–∫ –æ–∫–æ–Ω—á–∞–Ω–∏—è:</b> {real_end}\nüöö <b>–°—Ä–æ–∫ –¥–æ—Å—Ç–∞–≤–∫–∏:</b> {details['delivery_term']}\nüí∞ <b>–ù–∞—á–∞–ª—å–Ω–∞—è —Ü–µ–Ω–∞:</b> {start_price_str} UZS\nüìâ <b>–¢–µ–∫—É—â–∞—è —Ü–µ–Ω–∞:</b> {current_price_str}\nüîó <b>–°—Å—ã–ª–∫–∞:</b> {full_link}\n\nüè¢ <b>–ó–∞–∫–∞–∑—á–∏–∫:</b> {details['customer']}\nüìû <b>–ö–æ–Ω—Ç–∞–∫—Ç—ã:</b> {details['contact']}\nüë• <b>–£—á–∞—Å—Ç–Ω–∏–∫–æ–≤:</b> {details['participants']}\nüì¶ <b>–¢–æ–≤–∞—Ä—ã:</b>\n{details['items_desc'][:300]}...")
                    await send_notification_to_channel(msg, source_name, DEFAULT_PHOTO_PATH)
                    
                    save_to_google_sheet("Xarid.uz", [
                        datetime.now().strftime("%d.%m.%Y %H:%M"), "–ê—É–∫—Ü–∏–æ–Ω", lot_id, 
                        details['items_desc'], toifa, details['customer'], 
                        sheet_start_price,   # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ –Ω–∞ INT
                        sheet_current_price, # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ –Ω–∞ INT
                        region, real_start, real_end, 
                        details['delivery_term'], details['participants'], details['contact'], full_link
                    ])
                    new_items += 1
                except: continue
            if new_items == 0 and page_num > 1: break
            try:
                next_btn = page.locator(".pagination-next, .ui-paginator-next").first
                if await next_btn.is_visible(): await next_btn.click(); await page.wait_for_timeout(3000); page_num += 1
                else: break
            except: break
    except: pass

# ==========================================
# === 6. PARSING LOGIC: IT-MARKET ===
# ==========================================

async def parse_it_market(page):
    url = "https://it-market.uz/order/"
    source_name = "IT-Market"
    print(f"üîπ Checking {source_name}...")
    try:
        await page.goto(url, timeout=60000, wait_until="networkidle")
        cards = page.locator(".animated-card")
        if await cards.count() == 0: return
        for i in range(await cards.count()):
            card = cards.nth(i)
            try:
                link_loc = card.locator(".stretched-link")
                if await link_loc.count() > 0: href = await link_loc.get_attribute("href"); full_link = f"https://it-market.uz{href}"
                else: full_link = url
                if check_exists(full_link): continue
                lines = (await card.inner_text()).split('\n'); lines = [l.strip() for l in lines if l.strip()]
                if len(lines) < 3: continue
                company, status, title = lines[0], (lines[1] if len(lines) > 1 else ""), (lines[2] if len(lines) > 2 else "–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è")
                price_str = "–î–æ–≥–æ–≤–æ—Ä–Ω–∞—è"
                for k, line in enumerate(lines):
                    if "–ë—é–¥–∂–µ—Ç" in line and k+3 < len(lines): price_str = format_price_str(lines[k+3]); break
                add_tender_direct(source_name, title, company, price_str, "-", "-", full_link)
                print(f"üî• [IT-Market] New: {title}")
                msg = (f"<b>–¢–∏–ø –∞–Ω–∫–µ—Ç—ã: IT –ó–∞–∫–∞–∑</b>\n\nüè¢ <b>–ó–∞–∫–∞–∑—á–∏–∫:</b> {company}\n‚ÑπÔ∏è <b>–°—Ç–∞—Ç—É—Å:</b> {status}\nüõ† <b>–ó–∞–¥–∞—á–∞:</b> {title}\nüí∞ <b>–ë—é–¥–∂–µ—Ç:</b> {price_str}\nüîó <b>–°—Å—ã–ª–∫–∞:</b> {full_link}")
                await send_notification_to_channel(msg, source_name, DEFAULT_PHOTO_PATH)
                save_to_google_sheet("IT-Market", [datetime.now().strftime("%d.%m.%Y %H:%M"), company, status, title, price_str, full_link])
            except: continue
    except: pass

async def parser_loop():
    print("üöÄ Parser started in background...")
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True)
        context = await browser.new_context(viewport={'width': 1920, 'height': 1080})
        page = await context.new_page()
        while True:
            await parse_xarid_uz(page)
            await parse_etender(page)
            await parse_it_market(page)
            print("üí§ Parsing paused for 5 minutes...")
            await asyncio.sleep(300)

# ==========================================
# === 7. TELEGRAM BOT LOGIC ===
# ==========================================

def get_source_menu():
    kb = InlineKeyboardBuilder()
    kb.button(text="üèõ Xarid.uz", callback_data="source_Xarid.uz")
    kb.button(text="üèó Etender", callback_data="source_Etender")
    kb.button(text="ü§ù Cooperation", callback_data="source_Cooperation")
    kb.button(text="üè´ XT-Xarid", callback_data="source_XT-Xarid")
    kb.button(text="üíª IT-Market", callback_data="source_IT-Market")
    kb.adjust(2, 2, 1) 
    return kb.as_markup()

def get_bottom_menu():
    kb = ReplyKeyboardBuilder()
    kb.button(text="üîô –í—ã–±—Ä–∞—Ç—å –∏—Å—Ç–æ—á–Ω–∏–∫")
    kb.button(text="‚ù§Ô∏è –ú–æ–∏ –ª–∞–π–∫–∏")
    return kb.as_markup(resize_keyboard=True)

def get_tinder_keyboard(tender_id, source):
    kb = InlineKeyboardBuilder()
    kb.button(text="üëé –ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å", callback_data=f"dislike_{tender_id}_{source}")
    kb.button(text="‚ù§Ô∏è –õ–∞–π–∫", callback_data=f"like_{tender_id}_{source}")
    kb.adjust(2)
    return kb.as_markup()

def format_caption(source, title, desc, price, start, end, link):
    if source == "Xarid.uz":
        toifa, region, current_price = "–ù–µ —É–∫–∞–∑–∞–Ω–∞", "–ù–µ —É–∫–∞–∑–∞–Ω", "–ù–µ—Ç"
        if desc and "||" in desc:
            parts = desc.split("||")
            if len(parts) >= 3: toifa, region, current_price = parts[0], parts[1], parts[2]
        lot_number = title.replace("–õ–æ—Ç ‚Ññ", "").replace("–õ–æ—Ç ", "")
        return (f"üì¢ *–ù–æ–≤—ã–π –ª–æ—Ç –Ω–∞ Xarid.uz*\n\n1. *–ù–æ–º–µ—Ä –ª–æ—Ç–∞:* {lot_number}\n2. *–ö–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏—è:* {toifa}\n3. *–†–∞–π–æ–Ω:* {region}\n4. *–°—Ä–æ–∫ –æ–∫–æ–Ω—á–∞–Ω–∏—è:* {end}\n5. *–ù–∞—á–∞–ª—å–Ω–∞—è —Ü–µ–Ω–∞:* {price}\n6. *–¢–µ–∫—É—â–∞—è —Ü–µ–Ω–∞:* {current_price}\n7. *–°—Å—ã–ª–∫–∞:* {link}")
    
    elif source == "Etender":
        region = "–ù–µ —É–∫–∞–∑–∞–Ω"
        currency = ""
        if desc and "||" in desc:
             parts = desc.split("||")
             if len(parts) >= 2: region = parts[1]
             if len(parts) >= 3: currency = parts[2]
        lot_number = title.replace("–õ–æ—Ç ‚Ññ", "").replace("–õ–æ—Ç ", "")
        
        display_price = price if " " in price else f"{price} {currency}"
        return (f"üì¢ *–ù–æ–≤—ã–π –¢–µ–Ω–¥–µ—Ä –Ω–∞ Etender*\n\n1. *–ù–æ–º–µ—Ä –ª–æ—Ç–∞:* {lot_number}\n2. *–†–∞–π–æ–Ω:* {region}\n3. *–ù–∞—á–∞–ª–æ:* {start}\n4. *–ö–æ–Ω–µ—Ü:* {end}\n5. *–ë—é–¥–∂–µ—Ç:* {display_price}\n6. *–°—Å—ã–ª–∫–∞:* {link}")

    else:
        display_title = title if title else "–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è"
        company, status = desc, "-"
        if desc and "(" in desc and desc.strip().endswith(")"):
            try: company, status = desc.rsplit(" (", 1); status = status.replace(")", "")
            except: pass
        return (f"üì¢ *–ù–æ–≤—ã–π –∑–∞–∫–∞–∑ –Ω–∞ {source}*\n\nüè¢ *–ó–∞–∫–∞–∑—á–∏–∫:* {company}\n‚ÑπÔ∏è *–°—Ç–∞—Ç—É—Å:* {status}\nüõ† *–ó–∞–¥–∞—á–∞:* {display_title}\n\nüí∞ *–ë—é–¥–∂–µ—Ç:* {price}\nüìÖ *–ù–∞—á–∞–ª–æ:* {start}\nüèÅ *–î–µ–¥–ª–∞–π–Ω:* {end}\n\nüîó [–ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å –ø–æ–¥—Ä–æ–±–Ω–µ–µ]({link})")

@dp.message(Command("start"))
async def cmd_start(message: types.Message):
    await message.answer("üëã –ü—Ä–∏–≤–µ—Ç! –Ø –∞–≥—Ä–µ–≥–∞—Ç–æ—Ä —Ç–µ–Ω–¥–µ—Ä–æ–≤.", reply_markup=get_bottom_menu())
    await message.answer("üîé –û—Ç–∫—É–¥–∞ –±—Ä–∞—Ç—å —Ç–µ–Ω–¥–µ—Ä—ã?", reply_markup=get_source_menu())

@dp.message(F.text == "üîô –í—ã–±—Ä–∞—Ç—å –∏—Å—Ç–æ—á–Ω–∏–∫")
async def menu_button_handler(message: types.Message):
    await message.answer("üîé –í—ã–±–µ—Ä–∏—Ç–µ –ø–ª–æ—â–∞–¥–∫—É:", reply_markup=get_source_menu())

@dp.message(F.text == "‚ù§Ô∏è –ú–æ–∏ –ª–∞–π–∫–∏")
async def favorites_button_handler(message: types.Message):
    user_id = message.from_user.id
    favorites = get_user_favorites(user_id)
    if not favorites:
        await message.answer("üíî –í—ã –ø–æ–∫–∞ –Ω–∏—á–µ–≥–æ –Ω–µ –¥–æ–±–∞–≤–∏–ª–∏ –≤ –∏–∑–±—Ä–∞–Ω–Ω–æ–µ.")
        return
    await message.answer(f"üìã *–í–∞—à–∏ –∏–∑–±—Ä–∞–Ω–Ω—ã–µ ({len(favorites)} —à—Ç):*", parse_mode="Markdown")
    for row in favorites:
        t_id, title, price, link, source = row[:5]
        display_title = title if title else "–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è"
        text = f"üî¢ *{display_title}*\nüèõ {source}\nüí∞ {price}\nüîó {link}" if source in ["Xarid.uz", "Etender"] else f"üõ† *{display_title}*\nüèõ {source}\nüí∞ {price}\nüîó [–û—Ç–∫—Ä—ã—Ç—å]({link})"
        kb = InlineKeyboardBuilder()
        kb.button(text="üóë –£–¥–∞–ª–∏—Ç—å", callback_data=f"del_fav_{t_id}")
        await message.answer(text, parse_mode="Markdown", disable_web_page_preview=True, reply_markup=kb.as_markup())

@dp.callback_query(F.data.startswith("source_"))
async def start_swiping(callback: types.CallbackQuery):
    source_name = callback.data.split("_")[1]
    await callback.answer(f"–ó–∞–≥—Ä—É–∂–∞—é {source_name}...")
    await show_next_card(callback.message, callback.from_user.id, source_name)

async def show_next_card(message: types.Message, user_id, source_name):
    tender = get_next_tender(user_id, source_name)
    if not tender:
        await message.answer(f"üéâ –ù–∞ –ø–ª–æ—â–∞–¥–∫–µ *{source_name}* –≤—Å—ë –ø—Ä–æ—Å–º–æ—Ç—Ä–µ–Ω–æ!", parse_mode="Markdown")
        return
    t_id, title, desc, price, start, end, link = tender
    caption_text = format_caption(source_name, title, desc, price, start, end, link)
    if os.path.exists(DEFAULT_PHOTO_PATH):
        photo = FSInputFile(DEFAULT_PHOTO_PATH)
        await message.answer_photo(photo=photo, caption=caption_text, parse_mode="Markdown", reply_markup=get_tinder_keyboard(t_id, source_name))
    else:
        await message.answer(text=caption_text, parse_mode="Markdown", reply_markup=get_tinder_keyboard(t_id, source_name), disable_web_page_preview=True)

@dp.callback_query(F.data.startswith("like_"))
async def handle_like(callback: types.CallbackQuery):
    _, t_id, source = callback.data.split("_", 2)
    add_favorite(callback.from_user.id, t_id)
    old_text = callback.message.caption or callback.message.text
    link = get_tender_link(t_id)
    restored_text = old_text
    if link:
        if source == "Xarid.uz":
             if "7. –°—Å—ã–ª–∫–∞:" in old_text and link not in old_text: restored_text = old_text.replace("7. –°—Å—ã–ª–∫–∞:", f"7. –°—Å—ã–ª–∫–∞: {link}")
        elif source == "Etender":
             if "6. –°—Å—ã–ª–∫–∞:" in old_text and link not in old_text: restored_text = old_text.replace("6. –°—Å—ã–ª–∫–∞:", f"6. –°—Å—ã–ª–∫–∞: {link}")
        else: restored_text = old_text.replace("üîó –ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å –ø–æ–¥—Ä–æ–±–Ω–µ–µ", f"üîó [–ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å –ø–æ–¥—Ä–æ–±–Ω–µ–µ]({link})")
    new_text = f"{restored_text}\n\n‚úÖ *–í –ò–ó–ë–†–ê–ù–ù–û–ú*"
    if callback.message.photo: await callback.message.edit_caption(caption=new_text, parse_mode="Markdown", reply_markup=None)
    else: await callback.message.edit_text(text=new_text, parse_mode="Markdown", reply_markup=None, disable_web_page_preview=True)
    await callback.answer("‚ù§Ô∏è –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ")
    await show_next_card(callback.message, callback.from_user.id, source)

@dp.callback_query(F.data.startswith("dislike_"))
async def handle_dislike(callback: types.CallbackQuery):
    _, t_id, source = callback.data.split("_", 2)
    old_text = callback.message.caption or callback.message.text
    new_text = f"{old_text}\n\n‚ùå *–ü–†–û–ü–£–©–ï–ù–û*"
    if callback.message.photo: await callback.message.edit_caption(caption=new_text, parse_mode="Markdown", reply_markup=None)
    else: await callback.message.edit_text(text=new_text, parse_mode="Markdown", reply_markup=None, disable_web_page_preview=True)
    await callback.answer("üëé –ü—Ä–æ–ø—É—â–µ–Ω–æ")
    await show_next_card(callback.message, callback.from_user.id, source)

@dp.callback_query(F.data.startswith("del_fav_"))
async def delete_favorite_handler(callback: types.CallbackQuery):
    tender_id = callback.data.split("_")[2]
    delete_favorite(callback.from_user.id, tender_id)
    await callback.message.delete()
    await callback.answer("üóë –£–¥–∞–ª–µ–Ω–æ!")

# ==========================================
# === 8. MAIN (STARTUP) ===
# ==========================================

async def main():
    print("üöÄ Starting initialization...")
    try: init_db()
    except Exception as e:
        print(f"‚ùå CRITICAL DB ERROR: {e}")
        return
    print("ü§ñ Starting Bot and Parser...")
    asyncio.create_task(parser_loop())
    await dp.start_polling(bot)

if __name__ == "__main__":
    try: asyncio.run(main())
    except (KeyboardInterrupt, SystemExit): print("Bot stopped!")